#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„æ£€ç´¢æ€§èƒ½
éªŒè¯ retrieve_relevant_chunks æ–¹æ³•çš„æ”¹è¿›
"""

import time
import asyncio
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from app.services.advanced_retrieval import advanced_retrieval_service
from app.config.settings import DB_URL as DATABASE_URL
from app.config.logging_config import get_app_logger

logger = get_app_logger()

async def test_retrieval_performance():
    """æµ‹è¯•æ£€ç´¢æ€§èƒ½"""

    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db = SessionLocal()

    try:
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å¦‚ä½•ä¼˜åŒ–ç¥ç»ç½‘ç»œï¼Ÿ",
            "è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨",
            "æ¨èç³»ç»Ÿçš„ç®—æ³•"
        ]

        print("=" * 60)
        print("ğŸ” ä¼˜åŒ–åçš„æ£€ç´¢æ€§èƒ½æµ‹è¯•")
        print("=" * 60)

        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ“ æµ‹è¯•æŸ¥è¯¢ {i}: {query}")
            print("-" * 40)

            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()

            # æ‰§è¡Œæ£€ç´¢
            results = await advanced_retrieval_service.retrieve_relevant_chunks(
                db=db,
                query_text=query,
                top_k=5
            )

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            duration = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            print(f"â±ï¸  æ£€ç´¢æ—¶é—´: {duration:.2f}ms")
            print(f"ğŸ“Š è¿”å›ç»“æœæ•°: {len(results)}")

            # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
            for j, result in enumerate(results[:3], 1):
                similarity = result.get('similarity', 0)
                filename = result.get('filename', 'unknown')
                content_preview = result.get('content', '')[:100] + '...'

                print(f"  {j}. [{similarity:.4f}] {filename}")
                print(f"     {content_preview}")

            if not results:
                print("   âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

        print("\n" + "=" * 60)
        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
        print("=" * 60)

        # æµ‹è¯•æ•°æ®åº“ä¸­æ˜¯å¦æœ‰chunksæ•°æ®
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        print("-" * 30)

        chunk_count_query = text("SELECT COUNT(*) FROM document_chunks")
        embedding_count_query = text("SELECT COUNT(*) FROM document_chunks WHERE embedding IS NOT NULL")

        total_chunks = db.execute(chunk_count_query).scalar()
        embedded_chunks = db.execute(embedding_count_query).scalar()

        print(f"æ€»æ–‡æ¡£å—æ•°: {total_chunks}")
        print(f"å·²åµŒå…¥å—æ•°: {embedded_chunks}")
        print(f"åµŒå…¥ç‡: {(embedded_chunks/total_chunks*100):.1f}%" if total_chunks > 0 else "åµŒå…¥ç‡: 0%")

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    finally:
        db.close()

async def test_accuracy():
    """æµ‹è¯•æ£€ç´¢å‡†ç¡®æ€§"""
    print("\nğŸ¯ æ£€ç´¢å‡†ç¡®æ€§æµ‹è¯•")
    print("-" * 30)

    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db = SessionLocal()

    try:
        # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†æ•°æ˜¯å¦åˆç†
        query = "æœºå™¨å­¦ä¹ "
        results = await advanced_retrieval_service.retrieve_relevant_chunks(
            db=db,
            query_text=query,
            top_k=10
        )

        if results:
            print(f"æŸ¥è¯¢: {query}")
            print("å‰10ä¸ªç»“æœçš„ç›¸ä¼¼åº¦åˆ†æ•°:")

            for i, result in enumerate(results, 1):
                similarity = result.get('similarity', 0)
                print(f"  {i}. {similarity:.6f}")

            # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†å¸ƒ
            similarities = [r.get('similarity', 0) for r in results]
            avg_similarity = sum(similarities) / len(similarities)
            max_similarity = max(similarities)
            min_similarity = min(similarities)

            print(f"\nç›¸ä¼¼åº¦ç»Ÿè®¡:")
            print(f"  å¹³å‡å€¼: {avg_similarity:.4f}")
            print(f"  æœ€å¤§å€¼: {max_similarity:.4f}")
            print(f"  æœ€å°å€¼: {min_similarity:.4f}")

            # æ£€æŸ¥ç»“æœæ˜¯å¦æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
            is_descending = all(similarities[i] >= similarities[i+1] for i in range(len(similarities)-1))
            print(f"  é™åºæ’åˆ—: {'âœ…' if is_descending else 'âŒ'}")

    except Exception as e:
        logger.error(f"å‡†ç¡®æ€§æµ‹è¯•å¤±è´¥: {e}")
        print(f"âŒ å‡†ç¡®æ€§æµ‹è¯•å¤±è´¥: {e}")

    finally:
        db.close()

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¼˜åŒ–åçš„æ£€ç´¢æœåŠ¡...")

    try:
        await test_retrieval_performance()
        await test_accuracy()

        print("\nâœ¨ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\nğŸ’¥ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())