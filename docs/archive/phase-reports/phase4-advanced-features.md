# ç¬¬å››é˜¶æ®µ:é«˜çº§ç‰¹æ€§è¯¦ç»†ä»»åŠ¡

## é˜¶æ®µæ¦‚è§ˆ

**é˜¶æ®µåç§°**: é«˜çº§ç‰¹æ€§ä¸ä¼˜åŒ–
**é¢„è®¡å·¥æœŸ**: 3-4 å‘¨
**ç›®æ ‡**: æƒé™æ§åˆ¶ã€ç›‘æ§å‘Šè­¦ã€Rerankç²¾æ’ã€é«˜çº§åŠŸèƒ½
**å‰ç½®æ¡ä»¶**: ç¬¬ä¸‰é˜¶æ®µå®Œæˆ,åŸºç¡€æ£€ç´¢åŠŸèƒ½å¯ç”¨

---

## Week 1: æƒé™ä¸å®‰å…¨

### ä»»åŠ¡ 8.1: é¢†åŸŸçº§æƒé™æ§åˆ¶

**ä¼˜å…ˆçº§**: P0
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ç¬¬ä¸‰é˜¶æ®µå®Œæˆ

#### å­ä»»åŠ¡æ¸…å•

1. **å®ç°æƒé™æ£€æŸ¥æœåŠ¡**

   æ–‡ä»¶: `backend/app/services/domain_permission_service.py` (æ–°å»º)

   - [ ] **DomainPermissionService ç±»**
     ```python
     from typing import List, Optional
     from app.models.user import User
     from app.models.knowledge_domain import KnowledgeDomain

     class DomainPermissionService:
         """é¢†åŸŸæƒé™æœåŠ¡"""

         def __init__(self, db: Session):
             self.db = db

         async def check_permission(
             self,
             user: User,
             namespace: str,
             action: str  # 'read', 'write', 'admin'
         ) -> bool:
             """
             æ£€æŸ¥ç”¨æˆ·å¯¹é¢†åŸŸçš„æƒé™

             æƒé™è§„åˆ™:
             1. super_admin æ‹¥æœ‰æ‰€æœ‰æƒé™
             2. æ£€æŸ¥é¢†åŸŸçš„ permissions é…ç½®
             3. æ£€æŸ¥ç”¨æˆ·è§’è‰²æ˜¯å¦åœ¨æˆæƒåˆ—è¡¨ä¸­
             """

             # 1. Super Admin å…¨æƒé™
             if user.is_super_admin:
                 return True

             # 2. æŸ¥è¯¢é¢†åŸŸé…ç½®
             domain = self.db.query(KnowledgeDomain).filter(
                 KnowledgeDomain.namespace == namespace
             ).first()

             if not domain:
                 # é¢†åŸŸä¸å­˜åœ¨,æ‹’ç»è®¿é—®
                 return False

             if not domain.is_active:
                 # é¢†åŸŸå·²ç¦ç”¨,æ‹’ç»è®¿é—®
                 return False

             # 3. æ£€æŸ¥æƒé™é…ç½®
             permissions = domain.permissions or {}
             allowed_roles = permissions.get(action, [])

             if len(allowed_roles) == 0:
                 # æœªé…ç½®æƒé™,é»˜è®¤å…è®¸
                 return True

             # 4. æ£€æŸ¥ç”¨æˆ·è§’è‰²
             user_roles = [role.name for role in user.roles]

             for role_spec in allowed_roles:
                 # æ”¯æŒæ ¼å¼: 'role:admin', 'user:123', 'group:developers'
                 if role_spec.startswith('role:'):
                     role_name = role_spec[5:]
                     if role_name in user_roles:
                         return True

                 elif role_spec.startswith('user:'):
                     user_id = int(role_spec[5:])
                     if user.id == user_id:
                         return True

                 elif role_spec.startswith('group:'):
                     # é¢„ç•™:ç”¨æˆ·ç»„åŠŸèƒ½
                     pass

             return False

         async def get_accessible_domains(
             self,
             user: User,
             action: str = 'read'
         ) -> List[KnowledgeDomain]:
             """è·å–ç”¨æˆ·å¯è®¿é—®çš„é¢†åŸŸåˆ—è¡¨"""

             # Super Admin å¯è®¿é—®æ‰€æœ‰é¢†åŸŸ
             if user.is_super_admin:
                 return self.db.query(KnowledgeDomain).filter(
                     KnowledgeDomain.is_active == True
                 ).all()

             # æŸ¥è¯¢æ‰€æœ‰æ´»è·ƒé¢†åŸŸ
             domains = self.db.query(KnowledgeDomain).filter(
                 KnowledgeDomain.is_active == True
             ).all()

             # è¿‡æ»¤æœ‰æƒé™çš„é¢†åŸŸ
             accessible = []
             for domain in domains:
                 if await self.check_permission(user, domain.namespace, action):
                     accessible.append(domain)

             return accessible

         async def filter_results_by_permission(
             self,
             user: User,
             results: List[Tuple[DocumentChunk, str, float]]
         ) -> List[Tuple[DocumentChunk, str, float]]:
             """è¿‡æ»¤æ£€ç´¢ç»“æœ,ç§»é™¤æ— æƒè®¿é—®çš„é¢†åŸŸ"""

             filtered = []

             for chunk, namespace, score in results:
                 if await self.check_permission(user, namespace, 'read'):
                     filtered.append((chunk, namespace, score))

             return filtered
     ```

2. **é›†æˆåˆ°æŸ¥è¯¢ API**

   æ–‡ä»¶: `backend/app/routers/query.py`

   - [ ] **æ·»åŠ æƒé™æ£€æŸ¥**
     ```python
     @router.post("/query/v2")
     async def query_documents_v2(
         request: QueryRequest,
         db: Session = Depends(get_db),
         current_user: User = Depends(get_current_active_user)
     ):
         permission_service = DomainPermissionService(db)

         # 1. æ£€æŸ¥æŒ‡å®šé¢†åŸŸçš„è¯»æƒé™
         if request.namespace:
             has_permission = await permission_service.check_permission(
                 current_user,
                 request.namespace,
                 'read'
             )

             if not has_permission:
                 raise HTTPException(
                     status_code=403,
                     detail=f"æ— æƒè®¿é—®é¢†åŸŸ: {request.namespace}"
                 )

         # 2. æ‰§è¡Œæ£€ç´¢
         # ...

         # 3. è¿‡æ»¤ç»“æœ(ç§»é™¤æ— æƒè®¿é—®çš„é¢†åŸŸ)
         if retrieval_mode == 'cross':
             results_with_namespace = await permission_service.filter_results_by_permission(
                 current_user,
                 results_with_namespace
             )

         return response
     ```

3. **é›†æˆåˆ°ä¸Šä¼  API**

   æ–‡ä»¶: `backend/app/routers/upload.py`

   - [ ] **æ·»åŠ å†™æƒé™æ£€æŸ¥**
     ```python
     @router.post("/upload")
     async def upload_document(
         file: UploadFile,
         namespace: Optional[str] = Form('default'),
         ...
     ):
         permission_service = DomainPermissionService(db)

         # æ£€æŸ¥å†™æƒé™
         has_permission = await permission_service.check_permission(
             current_user,
             namespace,
             'write'
         )

         if not has_permission:
             raise HTTPException(
                 status_code=403,
                 detail=f"æ— æƒå‘é¢†åŸŸä¸Šä¼ æ–‡æ¡£: {namespace}"
             )

         # ç»§ç»­ä¸Šä¼ æµç¨‹
         # ...
     ```

4. **å‰ç«¯:é¢†åŸŸåˆ—è¡¨è¿‡æ»¤**

   æ–‡ä»¶: `frontend/src/components/domain/DomainSelector.vue`

   - [ ] **åªæ˜¾ç¤ºæœ‰æƒè®¿é—®çš„é¢†åŸŸ**
     ```javascript
     const loadDomains = async () => {
       try {
         // API ä¼šè‡ªåŠ¨è¿‡æ»¤æ— æƒè®¿é—®çš„é¢†åŸŸ
         const response = await getDomains({
           include_inactive: false,
           accessible_only: true  // æ–°å‚æ•°
         })
         domains.value = response.data
       } catch (error) {
         console.error('åŠ è½½é¢†åŸŸå¤±è´¥', error)
       }
     }
     ```

**äº¤ä»˜ç‰©**:
- âœ… DomainPermissionService å®ç°
- âœ… æŸ¥è¯¢å’Œä¸Šä¼  API æƒé™é›†æˆ
- âœ… å‰ç«¯é¢†åŸŸè¿‡æ»¤

---

### ä»»åŠ¡ 8.2: æ•æ„Ÿé¢†åŸŸä¿æŠ¤

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡æ—¶é—´**: 1.5 å¤©
**ä¾èµ–**: ä»»åŠ¡ 8.1

#### å­ä»»åŠ¡æ¸…å•

1. **æ·»åŠ æ•æ„Ÿæ ‡è®°å­—æ®µ**

   - [ ] **æ•°æ®åº“è¿ç§»**
     ```sql
     ALTER TABLE knowledge_domains
     ADD COLUMN is_sensitive BOOLEAN DEFAULT FALSE,
     ADD COLUMN require_mfa BOOLEAN DEFAULT FALSE,
     ADD COLUMN ip_whitelist JSONB DEFAULT '[]';
     ```

2. **æ•æ„Ÿé¢†åŸŸè®¿é—®æ§åˆ¶**

   æ–‡ä»¶: `backend/app/services/domain_permission_service.py`

   - [ ] **å¢å¼ºæƒé™æ£€æŸ¥**
     ```python
     async def check_sensitive_domain_access(
         self,
         user: User,
         domain: KnowledgeDomain,
         request: Request
     ) -> Tuple[bool, Optional[str]]:
         """
         æ£€æŸ¥æ•æ„Ÿé¢†åŸŸè®¿é—®

         Returns:
             (is_allowed, reason)
         """

         if not domain.is_sensitive:
             return True, None

         # 1. MFA æ£€æŸ¥
         if domain.require_mfa:
             if not user.mfa_verified:
                 return False, "æ•æ„Ÿé¢†åŸŸéœ€è¦å¤šå› ç´ è®¤è¯"

         # 2. IP ç™½åå•æ£€æŸ¥
         if domain.ip_whitelist and len(domain.ip_whitelist) > 0:
             client_ip = request.client.host

             if client_ip not in domain.ip_whitelist:
                 logger.warning(
                     f"IP {client_ip} å°è¯•è®¿é—®æ•æ„Ÿé¢†åŸŸ {domain.namespace}"
                 )
                 return False, f"IP {client_ip} ä¸åœ¨ç™½åå•ä¸­"

         # 3. æ—¶é—´çª—å£æ£€æŸ¥(å¯é€‰)
         # ...

         return True, None
     ```

3. **ç»“æœè„±æ•**

   æ–‡ä»¶: `backend/app/services/result_sanitizer.py` (æ–°å»º)

   - [ ] **è„±æ•æœåŠ¡**
     ```python
     class ResultSanitizer:
         """ç»“æœè„±æ•æœåŠ¡"""

         @staticmethod
         def sanitize_sensitive_content(
             content: str,
             sensitivity_level: str = 'high'
         ) -> str:
             """è„±æ•æ•æ„Ÿå†…å®¹"""

             if sensitivity_level == 'high':
                 # é«˜æ•æ„Ÿ:æ›¿æ¢æ•æ„Ÿè¯
                 patterns = [
                     (r'\d{11}', '***********'),  # æ‰‹æœºå·
                     (r'\d{17}[\dXx]', '******************'),  # èº«ä»½è¯
                     (r'\d{16,19}', '****************'),  # é“¶è¡Œå¡
                     (r'[\w.-]+@[\w.-]+', '***@***'),  # é‚®ç®±
                 ]

                 for pattern, replacement in patterns:
                     content = re.sub(pattern, replacement, content)

             elif sensitivity_level == 'medium':
                 # ä¸­æ•æ„Ÿ:éƒ¨åˆ†é®è”½
                 # ...
                 pass

             return content
     ```

4. **å®¡è®¡æ—¥å¿—**

   æ–‡ä»¶: `backend/app/services/audit_logger.py` (æ–°å»º)

   - [ ] **å®¡è®¡æ—¥å¿—æœåŠ¡**
     ```python
     class AuditLogger:
         """å®¡è®¡æ—¥å¿—"""

         @staticmethod
         async def log_sensitive_access(
             user: User,
             domain: KnowledgeDomain,
             action: str,
             query: Optional[str],
             ip: str,
             success: bool
         ):
             """è®°å½•æ•æ„Ÿé¢†åŸŸè®¿é—®æ—¥å¿—"""

             log_entry = AuditLog(
                 user_id=user.id,
                 username=user.username,
                 domain_namespace=domain.namespace,
                 action=action,
                 query_content=query,
                 ip_address=ip,
                 success=success,
                 timestamp=datetime.utcnow()
             )

             db.add(log_entry)
             db.commit()

             # åŒæ—¶è®°å½•åˆ°æ–‡ä»¶
             logger.info(
                 f"[AUDIT] User={user.username} Domain={domain.namespace} "
                 f"Action={action} IP={ip} Success={success}"
             )
     ```

**äº¤ä»˜ç‰©**:
- âœ… æ•æ„Ÿé¢†åŸŸæ ‡è®°å­—æ®µ
- âœ… æ•æ„Ÿè®¿é—®æ§åˆ¶
- âœ… ç»“æœè„±æ•æœåŠ¡
- âœ… å®¡è®¡æ—¥å¿—

---

## Week 2: ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### ä»»åŠ¡ 9.1: æŒ‡æ ‡é‡‡é›†ç³»ç»Ÿ

**ä¼˜å…ˆçº§**: P0
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ä»»åŠ¡ 8.2

#### å­ä»»åŠ¡æ¸…å•

1. **Prometheus æŒ‡æ ‡å¯¼å‡º**

   æ–‡ä»¶: `backend/app/monitoring/metrics.py` (æ–°å»º)

   - [ ] **å®šä¹‰æŒ‡æ ‡**
     ```python
     from prometheus_client import Counter, Histogram, Gauge

     # é¢†åŸŸæŸ¥è¯¢æŒ‡æ ‡
     domain_query_total = Counter(
         'domain_query_total',
         'Total number of queries per domain',
         ['namespace', 'retrieval_mode']
     )

     domain_query_latency = Histogram(
         'domain_query_latency_seconds',
         'Query latency per domain',
         ['namespace'],
         buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
     )

     domain_classification_accuracy = Gauge(
         'domain_classification_accuracy',
         'Classification accuracy per method',
         ['method']
     )

     domain_document_count = Gauge(
         'domain_document_count',
         'Number of documents per domain',
         ['namespace']
     )

     # ç¼“å­˜æŒ‡æ ‡
     cache_hit_rate = Gauge(
         'cache_hit_rate',
         'Cache hit rate',
         ['cache_type']
     )

     # æ•°æ®åº“æŒ‡æ ‡
     db_connection_pool_usage = Gauge(
         'db_connection_pool_usage',
         'Database connection pool usage percentage'
     )
     ```

   - [ ] **é›†æˆåˆ° API**
     ```python
     # åœ¨æŸ¥è¯¢ API ä¸­
     @router.post("/query/v2")
     async def query_documents_v2(...):
         start_time = time.time()

         try:
             # æ‰§è¡ŒæŸ¥è¯¢ 
             result = ...

             # è®°å½•æŒ‡æ ‡
             domain_query_total.labels(
                 namespace=namespace,
                 retrieval_mode=retrieval_mode
             ).inc()

             latency = time.time() - start_time
             domain_query_latency.labels(namespace=namespace).observe(latency)

             return result

         except Exception as e:
             # è®°å½•é”™è¯¯
             logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
             raise
     ```

2. **Prometheus ç«¯ç‚¹**

   æ–‡ä»¶: `backend/app/main.py`

   - [ ] **æ·»åŠ  /metrics ç«¯ç‚¹**
     ```python
     from prometheus_client import make_asgi_app

     # åˆ›å»º Prometheus ASGI app
     metrics_app = make_asgi_app()
     app.mount("/metrics", metrics_app)
     ```

3. **å®šæ—¶æ›´æ–°æŒ‡æ ‡**

   æ–‡ä»¶: `backend/app/monitoring/metric_updater.py` (æ–°å»º)

   - [ ] **åå°ä»»åŠ¡**
     ```python
     import asyncio
     from apscheduler.schedulers.asyncio import AsyncIOScheduler

     class MetricUpdater:
         """å®šæ—¶æ›´æ–°æŒ‡æ ‡"""

         def __init__(self, db: Session):
             self.db = db
             self.scheduler = AsyncIOScheduler()

         def start(self):
             """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""

             # æ¯5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡é¢†åŸŸæ–‡æ¡£æ•°
             self.scheduler.add_job(
                 self.update_domain_document_counts,
                 'interval',
                 minutes=5
             )

             # æ¯åˆ†é’Ÿæ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
             self.scheduler.add_job(
                 self.update_cache_metrics,
                 'interval',
                 minutes=1
             )

             self.scheduler.start()

         async def update_domain_document_counts(self):
             """æ›´æ–°é¢†åŸŸæ–‡æ¡£æ•°"""
             domains = self.db.query(KnowledgeDomain).all()

             for domain in domains:
                 count = self.db.query(Document).filter(
                     Document.namespace == domain.namespace
                 ).count()

                 domain_document_count.labels(
                     namespace=domain.namespace
                 ).set(count)

         async def update_cache_metrics(self):
             """æ›´æ–°ç¼“å­˜æŒ‡æ ‡"""
             # Redis ç¼“å­˜ç»Ÿè®¡
             redis_stats = redis_client.info('stats')
             hits = redis_stats.get('keyspace_hits', 0)
             misses = redis_stats.get('keyspace_misses', 0)

             if hits + misses > 0:
                 hit_rate = hits / (hits + misses)
                 cache_hit_rate.labels(cache_type='redis').set(hit_rate)
     ```

**äº¤ä»˜ç‰©**:
- âœ… Prometheus æŒ‡æ ‡å®šä¹‰
- âœ… /metrics ç«¯ç‚¹
- âœ… å®šæ—¶æŒ‡æ ‡æ›´æ–°

---

### ä»»åŠ¡ 9.2: Grafana ç›‘æ§å¤§ç›˜

**ä¼˜å…ˆçº§**: P0
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ä»»åŠ¡ 9.1

#### å­ä»»åŠ¡æ¸…å•

1. **åˆ›å»º Grafana Dashboard**

   æ–‡ä»¶: `monitoring/grafana/domain-dashboard.json` (æ–°å»º)

   - [ ] **é¢†åŸŸä½¿ç”¨æƒ…å†µé¢æ¿**
     - æ¯ä¸ªé¢†åŸŸçš„æŸ¥è¯¢é‡(æ—¶é—´åºåˆ—)
     - é¢†åŸŸæŸ¥è¯¢é‡åˆ†å¸ƒ(é¥¼å›¾)
     - é¢†åŸŸæ–‡æ¡£æ•°é‡(æ¡å½¢å›¾)

   - [ ] **æ€§èƒ½æŒ‡æ ‡é¢æ¿**
     - æŸ¥è¯¢å»¶è¿Ÿ P50/P95/P99(æ—¶é—´åºåˆ—)
     - åˆ†ç±»å»¶è¿Ÿ(æŒ‰æ–¹æ³•åˆ†ç»„)
     - æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡

   - [ ] **å‡†ç¡®æ€§æŒ‡æ ‡é¢æ¿**
     - åˆ†ç±»å‡†ç¡®ç‡(æŒ‰æ–¹æ³•)
     - è·¨é¢†åŸŸæ£€ç´¢ä½¿ç”¨ç‡
     - æ— ç»“æœæŸ¥è¯¢å æ¯”

   - [ ] **ç¼“å­˜æ•ˆç‡é¢æ¿**
     - ç¼“å­˜å‘½ä¸­ç‡
     - ç¼“å­˜å¤§å°
     - ç¼“å­˜æ¸…ç†é¢‘ç‡

2. **å‘Šè­¦è§„åˆ™**

   æ–‡ä»¶: `monitoring/grafana/alerts.yaml` (æ–°å»º)

   - [ ] **æ€§èƒ½å‘Šè­¦**
     ```yaml
     - alert: HighQueryLatency
       expr: domain_query_latency_seconds{quantile="0.95"} > 2
       for: 5m
       labels:
         severity: warning
       annotations:
         summary: "æŸ¥è¯¢å»¶è¿Ÿè¿‡é«˜"
         description: "é¢†åŸŸ {{ $labels.namespace }} çš„ P95 å»¶è¿Ÿè¶…è¿‡ 2 ç§’"

     - alert: LowClassificationAccuracy
       expr: domain_classification_accuracy < 0.7
       for: 10m
       labels:
         severity: warning
       annotations:
         summary: "åˆ†ç±»å‡†ç¡®ç‡ä¸‹é™"
         description: "{{ $labels.method }} åˆ†ç±»å‡†ç¡®ç‡ä½äº 70%"
     ```

   - [ ] **å¯ç”¨æ€§å‘Šè­¦**
     ```yaml
     - alert: HighQueryFailureRate
       expr: rate(domain_query_failures_total[5m]) > 0.05
       for: 5m
       labels:
         severity: critical
       annotations:
         summary: "æŸ¥è¯¢å¤±è´¥ç‡è¿‡é«˜"
         description: "é¢†åŸŸ {{ $labels.namespace }} æŸ¥è¯¢å¤±è´¥ç‡ > 5%"

     - alert: DatabaseConnectionPoolExhausted
       expr: db_connection_pool_usage > 0.9
       for: 5m
       labels:
         severity: critical
       annotations:
         summary: "æ•°æ®åº“è¿æ¥æ± è€—å°½"
     ```

3. **å¯¼å‡ºé…ç½®**

   - [ ] å¯¼å‡º Dashboard JSON
   - [ ] åˆ›å»ºéƒ¨ç½²è„šæœ¬
   - [ ] ç¼–å†™é…ç½®æ–‡æ¡£

**äº¤ä»˜ç‰©**:
- âœ… Grafana Dashboard JSON
- âœ… å‘Šè­¦è§„åˆ™é…ç½®
- âœ… éƒ¨ç½²æ–‡æ¡£

---

### ä»»åŠ¡ 9.3: æ—¥å¿—èšåˆä¸è¿½è¸ª

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ä»»åŠ¡ 9.2

#### å­ä»»åŠ¡æ¸…å•

1. **ç»“æ„åŒ–æ—¥å¿—**

   æ–‡ä»¶: `backend/app/utils/structured_logger.py` (æ–°å»º)

   - [ ] **æ—¥å¿—æ ¼å¼**
     ```python
     import structlog

     def configure_logging():
         structlog.configure(
             processors=[
                 structlog.stdlib.add_log_level,
                 structlog.stdlib.add_logger_name,
                 structlog.processors.TimeStamper(fmt="iso"),
                 structlog.processors.JSONRenderer()
             ],
             context_class=dict,
             logger_factory=structlog.stdlib.LoggerFactory(),
             cache_logger_on_first_use=True,
         )

     logger = structlog.get_logger()

     # ä½¿ç”¨ç¤ºä¾‹
     logger.info(
         "domain_classification",
         query="API è®¤è¯å¤±è´¥",
         namespace="technical_docs",
         confidence=0.88,
         method="hybrid",
         latency_ms=45
     )
     ```

2. **åˆ†å¸ƒå¼è¿½è¸ª(OpenTelemetry)**

   æ–‡ä»¶: `backend/app/tracing/tracer.py` (æ–°å»º)

   - [ ] **é…ç½® OpenTelemetry**
     ```python
     from opentelemetry import trace
     from opentelemetry.exporter.jaeger.thrift import JaegerExporter
     from opentelemetry.sdk.trace import TracerProvider
     from opentelemetry.sdk.trace.export import BatchSpanProcessor

     def configure_tracing(service_name: str = "rag-backend"):
         trace.set_tracer_provider(TracerProvider())

         jaeger_exporter = JaegerExporter(
             agent_host_name="localhost",
             agent_port=6831,
         )

         trace.get_tracer_provider().add_span_processor(
             BatchSpanProcessor(jaeger_exporter)
         )

     tracer = trace.get_tracer(__name__)

     # ä½¿ç”¨ç¤ºä¾‹
     with tracer.start_as_current_span("query_documents") as span:
         span.set_attribute("namespace", namespace)
         span.set_attribute("retrieval_mode", retrieval_mode)

         with tracer.start_as_current_span("domain_classification"):
             result = await classifier.classify(query)

         with tracer.start_as_current_span("retrieval"):
             chunks = await retrieval.search(query, namespace)

         with tracer.start_as_current_span("rerank"):
             ranked = await reranker.rerank(chunks)
     ```

3. **æ—¥å¿—æŸ¥è¯¢æ¥å£**

   æ–‡ä»¶: `backend/app/routers/monitoring.py` (æ–°å»º)

   - [ ] **æ—¥å¿—æŸ¥è¯¢ API**
     ```python
     @router.get("/monitoring/logs")
     async def get_logs(
         level: Optional[str] = None,
         start_time: Optional[datetime] = None,
         end_time: Optional[datetime] = None,
         limit: int = 100,
         current_user: User = Depends(require_admin)
     ):
         """æŸ¥è¯¢æ—¥å¿—(éœ€è¦ç®¡ç†å‘˜æƒé™)"""
         # ä»æ—¥å¿—æ–‡ä»¶æˆ– Elasticsearch æŸ¥è¯¢
         # ...
     ```

**äº¤ä»˜ç‰©**:
- âœ… ç»“æ„åŒ–æ—¥å¿—é…ç½®
- âœ… OpenTelemetry è¿½è¸ª
- âœ… æ—¥å¿—æŸ¥è¯¢ API

---

## Week 3: Rerank ç²¾æ’

### ä»»åŠ¡ 10.1: Reranker æ¨¡å‹é›†æˆ

**ä¼˜å…ˆçº§**: P0
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ä»»åŠ¡ 9.3

#### å­ä»»åŠ¡æ¸…å•

1. **Reranker æœåŠ¡**

   æ–‡ä»¶: `backend/app/services/reranker_service.py` (æ–°å»º)

   - [ ] **å®ç° Reranker**
     ```python
     from sentence_transformers import CrossEncoder

     class RerankerService:
         """Rerank ç²¾æ’æœåŠ¡"""

         def __init__(self):
             self.model_name = "BAAI/bge-reranker-v2-m3"
             self.model = None

         async def initialize(self):
             """åŠ è½½æ¨¡å‹"""
             self.model = CrossEncoder(self.model_name, max_length=512)
             logger.info(f"Reranker æ¨¡å‹å·²åŠ è½½: {self.model_name}")

         async def rerank(
             self,
             query: str,
             chunks: List[DocumentChunk],
             top_k: Optional[int] = None
         ) -> List[Tuple[DocumentChunk, float]]:
             """
             Rerank æ–‡æ¡£å—

             Args:
                 query: æŸ¥è¯¢æ–‡æœ¬
                 chunks: å€™é€‰æ–‡æ¡£å—
                 top_k: è¿”å›å‰ K ä¸ª(None = å…¨éƒ¨)

             Returns:
                 List[Tuple[chunk, score]]
             """

             if len(chunks) == 0:
                 return []

             # 1. æ„å»º query-chunk å¯¹
             pairs = [[query, chunk.content] for chunk in chunks]

             # 2. æ‰¹é‡æ¨ç†
             scores = self.model.predict(pairs)

             # 3. æ’åº
             chunk_scores = list(zip(chunks, scores))
             chunk_scores.sort(key=lambda x: x[1], reverse=True)

             # 4. è¿”å› Top-K
             if top_k is not None:
                 chunk_scores = chunk_scores[:top_k]

             return chunk_scores

         async def rerank_batch(
             self,
             queries: List[str],
             chunks_list: List[List[DocumentChunk]],
             top_k: int = 5
         ) -> List[List[Tuple[DocumentChunk, float]]]:
             """æ‰¹é‡ Rerank(å¹¶å‘ä¼˜åŒ–)"""

             tasks = [
                 self.rerank(query, chunks, top_k)
                 for query, chunks in zip(queries, chunks_list)
             ]

             results = await asyncio.gather(*tasks)
             return results
     ```

2. **é›†æˆåˆ°æ£€ç´¢æµç¨‹**

   æ–‡ä»¶: `backend/app/services/hybrid_retrieval.py`

   - [ ] **æ·»åŠ  Rerank æ­¥éª¤**
     ```python
     class HybridRetrieval:
         def __init__(self, db: Session, enable_rerank: bool = True):
             self.db = db
             self.vector_retrieval = VectorRetrieval(db)
             self.bm25_retrieval = BM25Retrieval(db)
             self.reranker = RerankerService() if enable_rerank else None

         async def search_by_namespace(
             self,
             query: str,
             namespace: str,
             top_k: int = 10,
             alpha: float = 0.5
         ) -> List[DocumentChunk]:
             # 1. æ··åˆæ£€ç´¢(è·å– Top-K * 3 å€™é€‰)
             candidates = await self._hybrid_search(
                 query,
                 namespace,
                 top_k * 3,
                 alpha
             )

             # 2. Rerank ç²¾æ’
             if self.reranker:
                 ranked = await self.reranker.rerank(query, candidates, top_k)
                 return [chunk for chunk, score in ranked]
             else:
                 return candidates[:top_k]
     ```

3. **æ€§èƒ½ä¼˜åŒ–**

   - [ ] **æ‰¹é‡æ¨ç†**
     ```python
     # Rerank æ¨¡å‹æ”¯æŒæ‰¹é‡æ¨ç†,å‡å°‘æ¨ç†æ¬¡æ•°
     batch_size = 32
     all_scores = []

     for i in range(0, len(pairs), batch_size):
         batch = pairs[i:i + batch_size]
         scores = self.model.predict(batch)
         all_scores.extend(scores)
     ```

   - [ ] **GPU åŠ é€Ÿ(å¯é€‰)**
   - [ ] **æ¨¡å‹é‡åŒ–(å¯é€‰)**

4. **å•å…ƒæµ‹è¯•**

   æ–‡ä»¶: `backend/tests/services/test_reranker.py`

   - [ ] æµ‹è¯• Rerank æ•ˆæœ
   - [ ] æµ‹è¯•æ‰¹é‡æ¨ç†
   - [ ] æµ‹è¯•æ€§èƒ½(å»¶è¿Ÿã€ååé‡)

**äº¤ä»˜ç‰©**:
- âœ… RerankerService å®ç°
- âœ… é›†æˆåˆ°æ£€ç´¢æµç¨‹
- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… å•å…ƒæµ‹è¯•

---

### ä»»åŠ¡ 10.2: Rerank æ•ˆæœè¯„ä¼°

**ä¼˜å…ˆçº§**: P1
**é¢„è®¡æ—¶é—´**: 1.5 å¤©
**ä¾èµ–**: ä»»åŠ¡ 10.1

#### å­ä»»åŠ¡æ¸…å•

1. **åˆ›å»ºè¯„ä¼°æ•°æ®é›†**

   æ–‡ä»¶: `backend/tests/data/rerank_test_set.json` (æ–°å»º)

   - [ ] **æ ‡æ³¨æ•°æ®é›†**
     ```json
     [
       {
         "query": "API è®¤è¯å¤±è´¥æ€ä¹ˆåŠ",
         "candidates": [
           {"chunk_id": 123, "relevance": 2},  // 2=é«˜åº¦ç›¸å…³
           {"chunk_id": 456, "relevance": 1},  // 1=éƒ¨åˆ†ç›¸å…³
           {"chunk_id": 789, "relevance": 0}   // 0=ä¸ç›¸å…³
         ]
       }
     ]
     ```

2. **è¯„ä¼°è„šæœ¬**

   æ–‡ä»¶: `backend/scripts/evaluate_rerank.py` (æ–°å»º)

   - [ ] **è¯„ä¼°æŒ‡æ ‡**
     ```python
     def evaluate_rerank(test_set, reranker):
         """è¯„ä¼° Rerank æ•ˆæœ"""

         # æŒ‡æ ‡
         ndcg_scores = []
         mrr_scores = []

         for case in test_set:
             query = case['query']
             chunks = load_chunks(case['candidates'])

             # Rerank
             ranked = reranker.rerank(query, chunks)

             # è®¡ç®— NDCG@5
             ndcg = calculate_ndcg(ranked, case['candidates'], k=5)
             ndcg_scores.append(ndcg)

             # è®¡ç®— MRR
             mrr = calculate_mrr(ranked, case['candidates'])
             mrr_scores.append(mrr)

         return {
             'ndcg@5': np.mean(ndcg_scores),
             'mrr': np.mean(mrr_scores)
         }
     ```

3. **å¯¹æ¯”æµ‹è¯•**

   - [ ] æ—  Rerank vs æœ‰ Rerank
   - [ ] ä¸åŒ Rerank æ¨¡å‹å¯¹æ¯”
   - [ ] ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

**äº¤ä»˜ç‰©**:
- âœ… Rerank è¯„ä¼°æ•°æ®é›†
- âœ… è¯„ä¼°è„šæœ¬
- âœ… è¯„ä¼°æŠ¥å‘Š

---

## Week 4: é«˜çº§åŠŸèƒ½

### ä»»åŠ¡ 11.1: é¢†åŸŸå…³ç³»ç®¡ç†

**ä¼˜å…ˆçº§**: P2
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ä»»åŠ¡ 10.2

#### å­ä»»åŠ¡æ¸…å•

1. **åˆ›å»ºé¢†åŸŸå…³ç³»è¡¨**

   - [ ] **æ•°æ®åº“è¿ç§»**
     ```sql
     CREATE TABLE domain_relationships (
         id SERIAL PRIMARY KEY,
         source_namespace VARCHAR(100) NOT NULL,
         related_namespace VARCHAR(100) NOT NULL,
         relationship_type VARCHAR(50) NOT NULL,
         weight FLOAT DEFAULT 0.5,
         is_active BOOLEAN DEFAULT TRUE,
         created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
         FOREIGN KEY (source_namespace) REFERENCES knowledge_domains(namespace),
         FOREIGN KEY (related_namespace) REFERENCES knowledge_domains(namespace),
         UNIQUE (source_namespace, related_namespace, relationship_type)
     );
     ```

2. **å…³ç³»ç®¡ç† API**

   æ–‡ä»¶: `backend/app/routers/domain_relationships.py` (æ–°å»º)

   - [ ] CRUD ç«¯ç‚¹
   - [ ] å…³ç³»æ¨èç®—æ³•

3. **æ™ºèƒ½è·¨é¢†åŸŸæ£€ç´¢**

   - [ ] åŸºäºå…³ç³»æƒé‡è°ƒæ•´æ£€ç´¢ç»“æœ
   - [ ] Fallback é¢†åŸŸé…ç½®

**äº¤ä»˜ç‰©**:
- âœ… é¢†åŸŸå…³ç³»è¡¨
- âœ… å…³ç³»ç®¡ç† API
- âœ… æ™ºèƒ½è·¨é¢†åŸŸæ£€ç´¢

---

### ä»»åŠ¡ 11.2: ä¼šè¯é¢†åŸŸä¸Šä¸‹æ–‡

**ä¼˜å…ˆçº§**: P2
**é¢„è®¡æ—¶é—´**: 1.5 å¤©
**ä¾èµ–**: ä»»åŠ¡ 11.1

#### å­ä»»åŠ¡æ¸…å•

1. **ä¼šè¯é¢†åŸŸè¿½è¸ª**

   - [ ] åœ¨ chat_sessions.metadata ä¸­è®°å½• current_namespace
   - [ ] è®°å½•é¢†åŸŸåˆ‡æ¢å†å²

2. **æ™ºèƒ½é¢†åŸŸå»¶ç»­**

   - [ ] å¤šè½®å¯¹è¯ä¸­å»¶ç»­å½“å‰é¢†åŸŸ
   - [ ] æ£€æµ‹é¢†åŸŸåˆ‡æ¢æ„å›¾

**äº¤ä»˜ç‰©**:
- âœ… ä¼šè¯é¢†åŸŸè¿½è¸ª
- âœ… æ™ºèƒ½é¢†åŸŸå»¶ç»­

---

### ä»»åŠ¡ 11.3: æ•°æ®åˆ†æä¸ä¼˜åŒ–å»ºè®®

**ä¼˜å…ˆçº§**: P2
**é¢„è®¡æ—¶é—´**: 2 å¤©
**ä¾èµ–**: ä»»åŠ¡ 11.2

#### å­ä»»åŠ¡æ¸…å•

1. **é¢†åŸŸä½¿ç”¨åˆ†ææŠ¥è¡¨**

   æ–‡ä»¶: `backend/app/routers/analytics.py` (æ–°å»º)

   - [ ] **GET /api/analytics/domain-usage** - é¢†åŸŸä½¿ç”¨ç»Ÿè®¡
   - [ ] **GET /api/analytics/classification-accuracy** - åˆ†ç±»å‡†ç¡®ç‡åˆ†æ
   - [ ] **GET /api/analytics/query-patterns** - æŸ¥è¯¢æ¨¡å¼åˆ†æ

2. **ä¼˜åŒ–å»ºè®®å¼•æ“**

   - [ ] è¯†åˆ«ä½æ–‡æ¡£æ•°é¢†åŸŸ,å»ºè®®è¡¥å……
   - [ ] è¯†åˆ«åˆ†ç±»æ··æ·†,å»ºè®®ä¼˜åŒ–å…³é”®è¯
   - [ ] è¯†åˆ«çƒ­ç‚¹æŸ¥è¯¢,å»ºè®®ç¼“å­˜

3. **å‰ç«¯åˆ†æé¡µé¢**

   æ–‡ä»¶: `frontend/src/views/admin/Analytics.vue` (æ–°å»º)

   - [ ] é¢†åŸŸä½¿ç”¨è¶‹åŠ¿å›¾è¡¨
   - [ ] åˆ†ç±»å‡†ç¡®ç‡é›·è¾¾å›¾
   - [ ] ä¼˜åŒ–å»ºè®®åˆ—è¡¨

**äº¤ä»˜ç‰©**:
- âœ… æ•°æ®åˆ†æ API
- âœ… ä¼˜åŒ–å»ºè®®å¼•æ“
- âœ… å‰ç«¯åˆ†æé¡µé¢

---

## é˜¶æ®µéªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- [ ] âœ… é¢†åŸŸçº§æƒé™æ§åˆ¶æ­£å¸¸å·¥ä½œ
- [ ] âœ… æ•æ„Ÿé¢†åŸŸè®¿é—®å—é™,å®¡è®¡æ—¥å¿—å®Œæ•´
- [ ] âœ… Prometheus + Grafana ç›‘æ§å¤§ç›˜å¯ç”¨
- [ ] âœ… Rerank ç²¾æ’æ•ˆæœæå‡ > 10% (NDCG@5)
- [ ] âœ… å‘Šè­¦è§„åˆ™è§¦å‘å¹¶é€šçŸ¥
- [ ] âœ… é¢†åŸŸå…³ç³»ç®¡ç†åŠŸèƒ½å¯ç”¨
- [ ] âœ… åˆ†ææŠ¥è¡¨æ•°æ®å‡†ç¡®

### è´¨é‡éªŒæ”¶

- [ ] âœ… å®‰å…¨å®¡è®¡é€šè¿‡
- [ ] âœ… æ€§èƒ½æµ‹è¯•è¾¾æ ‡
- [ ] âœ… ç›‘æ§è¦†ç›–ç‡ > 90%
- [ ] âœ… æ–‡æ¡£é½å…¨

### æ€§èƒ½éªŒæ”¶

- [ ] âœ… æƒé™æ£€æŸ¥å»¶è¿Ÿ < 10ms
- [ ] âœ… Rerank å»¶è¿Ÿ < 200ms (10ä¸ªå€™é€‰)
- [ ] âœ… ç›‘æ§æŒ‡æ ‡é‡‡é›†é—´éš” < 1s
- [ ] âœ… å‘Šè­¦å»¶è¿Ÿ < 5min

---

## é¡¹ç›®æ€»ç»“

å®Œæˆå››ä¸ªé˜¶æ®µå,å¤šé¢†åŸŸçŸ¥è¯†åº“ç³»ç»Ÿå°†å…·å¤‡:

### æ ¸å¿ƒåŠŸèƒ½
âœ… å‘½åç©ºé—´é¢†åŸŸéš”ç¦»
âœ… æ™ºèƒ½é¢†åŸŸåˆ†ç±»(å…³é”®è¯/LLM/æ··åˆ)
âœ… å•é¢†åŸŸå’Œè·¨é¢†åŸŸæ£€ç´¢
âœ… æ··åˆæ£€ç´¢(å‘é‡+BM25+RRF)
âœ… Rerank ç²¾æ’
âœ… é¢†åŸŸçº§æƒé™æ§åˆ¶

### é«˜çº§ç‰¹æ€§
âœ… æ•æ„Ÿé¢†åŸŸä¿æŠ¤
âœ… å®Œæ•´ç›‘æ§å‘Šè­¦ä½“ç³»
âœ… é¢†åŸŸå…³ç³»ç®¡ç†
âœ… ä¼šè¯é¢†åŸŸä¸Šä¸‹æ–‡
âœ… æ•°æ®åˆ†æä¸ä¼˜åŒ–å»ºè®®

### æ€§èƒ½æŒ‡æ ‡
- åˆ†ç±»å‡†ç¡®ç‡ > 88%
- å•é¢†åŸŸæ£€ç´¢å»¶è¿Ÿ P95 < 500ms
- è·¨é¢†åŸŸæ£€ç´¢å»¶è¿Ÿ P95 < 1.5s
- Rerank æ•ˆæœæå‡ > 10%
- ç³»ç»Ÿå¯ç”¨æ€§ > 99.5%

æ­å–œå®Œæˆå¤šé¢†åŸŸçŸ¥è¯†åº“æ¶æ„çš„å®Œæ•´å®æ–½! ğŸ‰
